{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "%pip install pdfplumber\r\n",
        "import requests\r\n",
        "import pdfplumber\r\n",
        "import tempfile\r\n",
        "import re\r\n",
        "from pyspark.sql.functions import lit,trim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "blob_relative_path = 'www.sba.gov/sites/sbagov/files/2023-01'\r\n",
        "from pyspark.sql import SparkSession \r\n",
        "from pyspark.sql.types import * \r\n",
        "from pyspark.sql.functions import split,col,substring,expr,first\r\n",
        "import concurrent.futures\r\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\n",
        "# Azure storage access info \r\n",
        "\r\n",
        "blob_account_name = 'usafactsbronze' # replace with your blob name \r\n",
        "blob_container_name = 'bronze' # replace with your container name \r\n",
        "linked_service_name = 'bronze' # replace with your linked service name \r\n",
        "\r\n",
        "blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name) \r\n",
        "\r\n",
        "# Allow SPARK to access from Blob remotely \r\n",
        "bronze_wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token) \r\n",
        "\r\n",
        "blob_service_client = BlobServiceClient(\"https://{}.blob.core.windows.net\".format(blob_account_name), credential=blob_sas_token)\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def get_file_paths(dir_path):\r\n",
        "    file_paths = []\r\n",
        "\r\n",
        "    def recursive_search(directory):\r\n",
        "        files = mssparkutils.fs.ls(directory)\r\n",
        "        for file in files:\r\n",
        "            if file.isDir:\r\n",
        "                recursive_search(file.path)\r\n",
        "            else:\r\n",
        "                if file.path.endswith(('.pdf')):\r\n",
        "                    path = file.path.split(dir_path.split(blob_relative_path)[0])[-1]\r\n",
        "                    file_paths.append(path)\r\n",
        "    \r\n",
        "    recursive_search(dir_path)\r\n",
        "    return file_paths\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "blob_relative_path = 'www.sba.gov/sites/sbagov/files/2023-01'\r\n",
        "blob_account_name = 'usafactssilver' # replace with your blob name \r\n",
        "blob_container_name = 'silver' # replace with your container name \r\n",
        "linked_service_name = 'silver' # replace with your linked service name \r\n",
        "\r\n",
        "blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name) \r\n",
        "\r\n",
        "# Allow SPARK to access from Blob remotely \r\n",
        "silver_wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token) \r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "print(silver_wasbs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "links = get_file_paths(bronze_wasbs_path)\r\n",
        "print(len(links))\r\n",
        "print(links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def exclude_and_return(data):\r\n",
        "    remaining_lists = []\r\n",
        "    exclude_mode = False\r\n",
        "\r\n",
        "    for sublist in data:\r\n",
        "        if not exclude_mode and isinstance(sublist, list) and sublist[0] == 'This':\r\n",
        "            exclude_mode = True\r\n",
        "        elif exclude_mode and isinstance(sublist, list) and sublist[-1] == 'programs.':\r\n",
        "            exclude_mode = False\r\n",
        "        elif not exclude_mode:\r\n",
        "            remaining_lists.append(sublist)\r\n",
        "\r\n",
        "    return remaining_lists if not exclude_mode else None\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def process_list_of_lists(list_of_lists,length):\r\n",
        "    result = []\r\n",
        "    l = length - 1\r\n",
        "    for inner_list in list_of_lists:\r\n",
        "        if len(inner_list) == length:\r\n",
        "            result.append(inner_list)\r\n",
        "        elif len(inner_list) > length:\r\n",
        "            #concat_list = inner_list[:-1] + inner_list[-2:10:-1]\r\n",
        "            remaining = inner_list[-l:]\r\n",
        "            #print(remaining)\r\n",
        "            concat_list = ['_'.join(inner_list[:-l])] + remaining\r\n",
        "            result.append(concat_list)\r\n",
        "        elif 1 <= len(inner_list) <= 3:\r\n",
        "            concat_list = ['_'.join(inner_list)]\r\n",
        "            result.append(concat_list)\r\n",
        "    \r\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def process_first_column(out):\r\n",
        "    if isinstance(out[0], list) and len(out[1]) == 1:\r\n",
        "        index_gb = -1\r\n",
        "        for i, sublist in enumerate(out):\r\n",
        "            if 'Guarantied_Business' in sublist:\r\n",
        "                index_gb = i\r\n",
        "                break\r\n",
        "        if index_gb != -1:\r\n",
        "            gb = out[index_gb][0]  # Extract 'Guarantied_Business'\r\n",
        "            for i in range(index_gb + 1, len(out)):\r\n",
        "                if len(out[i]) == 1:\r\n",
        "                    out[i][0] = '_'.join([gb] + out[i])\r\n",
        "        output = []\r\n",
        "        current_key = ''\r\n",
        "        for item in out[1:]:\r\n",
        "            if len(item) == 1:\r\n",
        "                current_key = item[0]\r\n",
        "            else:\r\n",
        "                output.append([f'{current_key}_{item[0]}'] + item[1:])\r\n",
        "    else:\r\n",
        "        output = []\r\n",
        "        current_key = ''\r\n",
        "\r\n",
        "        for item in out:\r\n",
        "            if len(item) == 1:\r\n",
        "                current_key = item[0]\r\n",
        "            else:\r\n",
        "                output.append([f'{current_key}_{item[0]}'] + item[1:])\r\n",
        "        # for i in output:\r\n",
        "        #     print(i)\r\n",
        "    return output\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def process_2_length_1(data):\r\n",
        "    new_list = []\r\n",
        "    i = 0\r\n",
        "    while i in range(len(data) - 1):\r\n",
        "    #while i < len(data) - 1:\r\n",
        "        sublist = data[i]\r\n",
        "        next_sublist = data[i + 1] if i + 1 < len(data) else None\r\n",
        "        if len(sublist) == 1 and next_sublist and len(next_sublist) > 1:\r\n",
        "            temp = sublist[0]  # Grabbing the only element from the current sublist\r\n",
        "            #new_list.append([f'{temp}_{next_sublist[0]}'] + next_sublist[1:])        \r\n",
        "            #new_list.append(l)\r\n",
        "            i+=1\r\n",
        "            while i < len(data) and len(data[i]) > 1:\r\n",
        "                #temp = merged\r\n",
        "                #temp = merged[0].split('_')[1]\r\n",
        "                merged = [f'{temp}_{data[i][0]}'] + data[i][1:]\r\n",
        "                i += 1        \r\n",
        "                new_list.append(merged)\r\n",
        "        else:\r\n",
        "            new_list.append(sublist)\r\n",
        "            i += 1       \r\n",
        "\r\n",
        "    output = []\r\n",
        "    current_key = ''\r\n",
        "\r\n",
        "    for item in new_list:\r\n",
        "        if len(item) == 1:\r\n",
        "            current_key = item[0]\r\n",
        "        else:\r\n",
        "            output.append([f'{current_key}_{item[0]}'] + item[1:])\r\n",
        "    # for i in output:\r\n",
        "    #     print(i)\r\n",
        "    return output\r\n",
        "    #print(new_list)    \r\n",
        "    # for l in new_list:\r\n",
        "    #     print(l)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\r\n",
        "links = ['www.sba.gov/sites/sbagov/files/2023-01/WDS_PostChargeOffRecoveryRates_Report_20221231-508.pdf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "import pandas as pd\r\n",
        "from pyspark.sql.functions import when,col,lit\r\n",
        "bad_records = []\r\n",
        "for i in links:\r\n",
        "    try:\r\n",
        "        url = f'https://usafactsbronze.blob.core.windows.net/bronze/{i}'\r\n",
        "        print(url)\r\n",
        "        response = requests.get(url)\r\n",
        "        pdf_file = response.content\r\n",
        "        #print(pdf_file)\r\n",
        "        with tempfile.NamedTemporaryFile(suffix='.pdf') as tmp_file:\r\n",
        "            tmp_file.write(pdf_file)\r\n",
        "            tmp_file.seek(0)\r\n",
        "            with pdfplumber.open(tmp_file.name) as pdf:\r\n",
        "                pages = pdf.pages\r\n",
        "                df2 = None\r\n",
        "                full_data = []\r\n",
        "                for page in pages :\r\n",
        "                    tables = page.extract_text()\r\n",
        "                    full_data.append(tables)\r\n",
        "\r\n",
        "        #print(full_data)\r\n",
        "\r\n",
        "        result_string = [', '.join(full_data).replace(' ', ';').replace('\\n', ';')]\r\n",
        "        result_lists = [tuple(s.split(';')) for s in result_string]\r\n",
        "        #print(result_lists)\r\n",
        "\r\n",
        "        original_list = [element.strip(',') for element in result_lists[0]]\r\n",
        "        #print(original_list)\r\n",
        "\r\n",
        "        end_index = original_list.index('programs.')\r\n",
        "        start_index = original_list.index('This')  # Adding 1 to make sure end_index is greater than start_index\r\n",
        "\r\n",
        "        end_index1 = original_list.index('Year')\r\n",
        "        start_index1 = original_list.index('Table')\r\n",
        "        #extracted_data = [row[start_index:end_index] for row in original_list]\r\n",
        "        Header_data = original_list[start_index1:end_index1 +1]\r\n",
        "        footer_data = original_list[start_index:end_index +1]\r\n",
        "        Header_data = ' '.join(Header_data)\r\n",
        "        #print(Header_data)\r\n",
        "        footer_data = ' '.join(footer_data)\r\n",
        "        #print(footer_data)\r\n",
        "\r\n",
        "        # Split the data into lines\r\n",
        "        consolidatad_data = []\r\n",
        "        for data in full_data:    \r\n",
        "            lines = data.split('\\n')\r\n",
        "            #consolidatad_data.append(lines)\r\n",
        "            #print(lines)\r\n",
        "            \r\n",
        "            for data in lines:\r\n",
        "                #for i in data:\r\n",
        "                consolidatad_data.append(data)\r\n",
        "        #print(consolidatad_data)\r\n",
        "\r\n",
        "        #for liness in lines:\r\n",
        "        converted_data1 = [[c for c in item.split()] for item in consolidatad_data]\r\n",
        "        converted_data = [sublist for sublist in converted_data1 if len(sublist) > 1 or any(len(str(item)) > 1 for item in sublist if isinstance(item, str))]\r\n",
        "        #print(converted_data)\r\n",
        "        column_header = (converted_data[2])\r\n",
        "\r\n",
        "        ##### Column Header creation\r\n",
        "        index = next((i for i, item in enumerate(column_header) if item.isdigit()), None)\r\n",
        "        # Concatenate elements before the first numeric element\r\n",
        "        concatenated = ['_'.join(column_header[:index])] + column_header[index:]\r\n",
        "        #print(concatenated)\r\n",
        "        #print(len(concatenated)-1)\r\n",
        "        length = len(concatenated)\r\n",
        "        #print(length)\r\n",
        "\r\n",
        "        result = exclude_and_return(converted_data)\r\n",
        "        filtered_list = [lst for lst in result if lst[0] not in ['Table', 'Fiscal', 'Purchase','Program','Charge']]\r\n",
        "\r\n",
        "        datas = []\r\n",
        "        for inner_list in filtered_list:\r\n",
        "            if '(' in inner_list[0]:\r\n",
        "                datas.append(inner_list)\r\n",
        "            else:    \r\n",
        "                inner_list[:] = [word for word in inner_list if '(' not in word]\r\n",
        "                inner_list = [word.replace(')', '') for word in inner_list]\r\n",
        "                datas.append(inner_list)\r\n",
        "        #print(datas)\r\n",
        "        out = process_list_of_lists(datas,length)\r\n",
        "        #print(out)\r\n",
        "        if len(out[0]) == 1 and len(out[1]) == 1:            \r\n",
        "            x = process_2_length_1(out)\r\n",
        "            #print(x)\r\n",
        "        else:\r\n",
        "            x = process_first_column(out)\r\n",
        "        x =[sublist if not any(keyword in sublist[0] for keyword in ['Subtotal', 'Total']) else ['Subtotal' if 'Subtotal' in sublist[0] else 'Total'] + sublist[1:] for sublist in x]\r\n",
        "        #print(x)\r\n",
        "        data_frame = pd.DataFrame(x,columns=concatenated)\r\n",
        "        #display(data_frame)\r\n",
        "        spark_df = spark.createDataFrame(data_frame)\r\n",
        "        spark_df = spark_df.withColumn(\"Header\", lit(Header_data)).withColumn(\"Footer\", lit(footer_data))\r\n",
        "        silver_wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
        "        spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token)\r\n",
        "        file_location = silver_wasbs_path + '/' + Header_data\r\n",
        "        spark_df.write.format('delta').mode('overwrite').option(\"overwriteSchema\", \"true\").option(\"path\",file_location).save()\r\n",
        "        print(file_location,'sucessfully uploaded')\r\n",
        "        display(spark_df)\r\n",
        "    except BaseException as e :\r\n",
        "        bad_records.append((url,url.split('/')[-1],e))\r\n",
        "        #bad_records.append(i)\r\n",
        "        #bad_records.append((e))\r\n",
        "        print(e)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "print(bad_records)"
      ]
    }
  ]
}